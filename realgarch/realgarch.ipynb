{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd00a1bd-ea44-426c-a0ae-b59273511141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "def _safelog(x, eps=1e-12):\n",
    "    return np.log(np.clip(np.asarray(x, float), eps, None))\n",
    "\n",
    "def qlike(f, y, eps=1e-12):\n",
    "    f = np.clip(np.asarray(f, float), eps, None)\n",
    "    y = np.asarray(y, float)\n",
    "    return np.mean(np.log(f) + y/f)\n",
    "\n",
    "def mse(yhat, y):\n",
    "    yhat = np.asarray(yhat, float); y = np.asarray(y, float)\n",
    "    return np.mean((yhat - y)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559b5391-1daf-4b85-a2e2-b018e38c6161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RV_daily</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-01-02</th>\n",
       "      <td>0.140261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-03</th>\n",
       "      <td>0.082399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>0.211454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>0.022647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-09</th>\n",
       "      <td>0.228727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RV_daily\n",
       "date                \n",
       "1996-01-02  0.140261\n",
       "1996-01-03  0.082399\n",
       "1996-01-04  0.211454\n",
       "1996-01-05  0.022647\n",
       "1996-01-09  0.228727"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv = pd.read_csv('SPY.csv')\n",
    "rv = rv[[\"Date\", \"Volatility\", \"Type\"]]\n",
    "rv.rename(columns={\"Volatility\": \"RV_daily\"},inplace=True)\n",
    "rv = rv[rv['Type'] == 'QMLE-Trade']\n",
    "rv.drop(columns=['Type'], inplace=True)\n",
    "rv = rv.set_index(\"Date\")\n",
    "rv.index = pd.to_datetime(rv.index)\n",
    "rv.index.name = \"date\"\n",
    "\n",
    "rv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adff59d5-a783-4ffa-a88a-f33eab971553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-01-02</th>\n",
       "      <td>0.010673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-03</th>\n",
       "      <td>0.002766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>-0.009529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>-0.002025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-08</th>\n",
       "      <td>0.003805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   r\n",
       "date                \n",
       "1996-01-02  0.010673\n",
       "1996-01-03  0.002766\n",
       "1996-01-04 -0.009529\n",
       "1996-01-05 -0.002025\n",
       "1996-01-08  0.003805"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns (CRSP) → ret  (PERMNO = 84398, date is DD/MM/YYYY)\n",
    "ret = pd.read_csv(\"returns (crsp).csv\")\n",
    "ret.columns = ret.columns.str.strip()\n",
    "\n",
    "# pick columns that really exist in this file\n",
    "date_col = \"date\" if \"date\" in ret.columns else \"Date\"\n",
    "ret_col  = \"RET\" if \"RET\" in ret.columns else \"RETX\"  # prefer RET, fallback to RETX\n",
    "\n",
    "ret = ret[[date_col, \"PERMNO\", ret_col]].copy()\n",
    "ret = ret[ret[\"PERMNO\"] == 84398].drop(columns=[\"PERMNO\"])\n",
    "\n",
    "# parse dates BEFORE setting the index (DD/MM/YYYY)\n",
    "ret[date_col] = pd.to_datetime(ret[date_col], format=\"%d/%m/%Y\", errors=\"raise\")\n",
    "ret = ret.sort_values(date_col).set_index(date_col)\n",
    "ret.index.name = \"date\"\n",
    "\n",
    "# make numeric returns (handles 'C','B','' etc.), create r\n",
    "ret[\"r\"] = pd.to_numeric(ret[ret_col], errors=\"coerce\")\n",
    "ret.drop(columns=[ret_col], inplace=True)\n",
    "ret.dropna(subset=[\"r\"], inplace=True)\n",
    "\n",
    "# cap to last available date you mentioned\n",
    "ret = ret.loc[:\"2024-12-29\"]\n",
    "\n",
    "ret.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db14a8d5-b1f5-4ab2-8464-078be93051be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RV_daily</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-01-02</th>\n",
       "      <td>0.140261</td>\n",
       "      <td>0.010673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-03</th>\n",
       "      <td>0.082399</td>\n",
       "      <td>0.002766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>0.211454</td>\n",
       "      <td>-0.009529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>0.022647</td>\n",
       "      <td>-0.002025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-09</th>\n",
       "      <td>0.228727</td>\n",
       "      <td>-0.017185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RV_daily         r\n",
       "date                          \n",
       "1996-01-02  0.140261  0.010673\n",
       "1996-01-03  0.082399  0.002766\n",
       "1996-01-04  0.211454 -0.009529\n",
       "1996-01-05  0.022647 -0.002025\n",
       "1996-01-09  0.228727 -0.017185"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = rv.join(ret, how=\"inner\").dropna()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9155d49c-00bb-49a5-a958-e1213c7789a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealizedGARCH11:\n",
    "    def __init__(self):\n",
    "        self.theta_ = None\n",
    "        self.success_ = None\n",
    "        self.info_ = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def _negloglik(theta, r, x):\n",
    "        omega, beta, gamma, xi, phi, tau1, tau2, log_sigma_u2 = theta\n",
    "        sigma_u2 = np.exp(log_sigma_u2)\n",
    "\n",
    "        r = np.asarray(r, float); x = np.asarray(x, float)\n",
    "        T = len(r)\n",
    "        if T < 20: return 1e12\n",
    "\n",
    "        logx = _safelog(x)\n",
    "        logh = np.empty(T)\n",
    "        init_var = max(np.var(r), 1e-8)\n",
    "        logh[0] = np.log(init_var)\n",
    "\n",
    "        ll = 0.0\n",
    "        two_pi = 2*np.pi\n",
    "\n",
    "        for t in range(1, T):\n",
    "            logh[t] = omega + beta*logh[t-1] + gamma*logx[t-1]\n",
    "            h_t = np.exp(logh[t])\n",
    "\n",
    "            # r_t | h_t\n",
    "            ll_r = -0.5*(np.log(two_pi) + np.log(h_t) + (r[t]**2)/h_t)\n",
    "\n",
    "            # z_t\n",
    "            z_t = r[t]/np.sqrt(h_t)\n",
    "\n",
    "            # log x_t | h_t, z_t\n",
    "            mu_x = xi + phi*logh[t] + tau1*z_t + tau2*(z_t**2 - 1.0)\n",
    "            e_t = logx[t] - mu_x\n",
    "            ll_x = -0.5*(np.log(two_pi) + np.log(sigma_u2) + (e_t**2)/sigma_u2)\n",
    "\n",
    "            ll += (ll_r + ll_x)\n",
    "\n",
    "        return -ll if np.isfinite(ll) else 1e12\n",
    "\n",
    "    def fit(self, r, x, start=None, bounds=None, options=None):\n",
    "        r = np.asarray(r, float); x = np.asarray(x, float)\n",
    "\n",
    "        if start is None:\n",
    "            start = np.array([\n",
    "                -0.1,   # omega\n",
    "                 0.95,  # beta\n",
    "                 0.05,  # gamma\n",
    "                 0.0,   # xi\n",
    "                 1.0,   # phi\n",
    "                 0.0,   # tau1\n",
    "                 0.0,   # tau2\n",
    "                -2.0    # log_sigma_u2\n",
    "            ], float)\n",
    "\n",
    "        if bounds is None:\n",
    "            bounds = [\n",
    "                (-5.0,   5.0),   # omega\n",
    "                ( 0.00,  0.999), # beta\n",
    "                ( 0.00,  2.0),   # gamma\n",
    "                (-5.0,   5.0),   # xi\n",
    "                ( 0.5,   1.5),   # phi\n",
    "                (-2.0,   2.0),   # tau1\n",
    "                (-2.0,   2.0),   # tau2\n",
    "                (-12.0,  5.0)    # log_sigma_u2\n",
    "            ]\n",
    "\n",
    "        res = minimize(self._negloglik, start, args=(r,x),\n",
    "                       method=\"L-BFGS-B\", bounds=bounds,\n",
    "                       options={\"maxiter\": 2000, \"ftol\": 1e-10, **(options or {})})\n",
    "        self.theta_ = res.x\n",
    "        self.success_ = res.success\n",
    "        self.info_ = {\"opt\": res}\n",
    "        return self\n",
    "\n",
    "    def filter_in_sample(self, r, x, theta=None):\n",
    "        if theta is None: theta = self.theta_\n",
    "        omega, beta, gamma, xi, phi, tau1, tau2, log_sigma_u2 = theta\n",
    "\n",
    "        r = np.asarray(r, float); x = np.asarray(x, float)\n",
    "        T = len(r)\n",
    "        logx = _safelog(x)\n",
    "\n",
    "        logh = np.empty(T)\n",
    "        init_var = max(np.var(r), 1e-8)\n",
    "        logh[0] = np.log(init_var)\n",
    "\n",
    "        z = np.zeros(T); u = np.zeros(T)\n",
    "        for t in range(1, T):\n",
    "            logh[t] = omega + beta*logh[t-1] + gamma*logx[t-1]\n",
    "            h_t = np.exp(logh[t])\n",
    "            z[t] = r[t]/np.sqrt(h_t)\n",
    "            mu_x = xi + phi*logh[t] + tau1*z[t] + tau2*(z[t]**2 - 1.0)\n",
    "            u[t] = logx[t] - mu_x\n",
    "\n",
    "        return logh, np.exp(logh), z, u, np.exp(log_sigma_u2)\n",
    "\n",
    "    def forecast_oos(self, r_train, x_train, x_test):\n",
    "        theta = self.theta_\n",
    "        omega, beta, gamma, xi, phi, tau1, tau2, log_sigma_u2 = theta\n",
    "\n",
    "        r_train = np.asarray(r_train, float); x_train = np.asarray(x_train, float); x_test = np.asarray(x_test, float)\n",
    "\n",
    "        logh_tr, _, _, _, _ = self.filter_in_sample(r_train, x_train, theta=theta)\n",
    "        last_logh = logh_tr[-1]\n",
    "        last_logx = _safelog(x_train[-1])\n",
    "\n",
    "        logh_fore = np.empty(len(x_test))\n",
    "        x_pred = np.empty(len(x_test))\n",
    "\n",
    "        for i in range(len(x_test)):\n",
    "            logh_t = omega + beta*last_logh + gamma*last_logx\n",
    "            h_t = np.exp(logh_t)\n",
    "            logh_fore[i] = logh_t\n",
    "\n",
    "            # E[log x_t | F_{t-1}] uses E[z_t]=0, E[z_t^2-1]=0\n",
    "            logx_pred = xi + phi*logh_t\n",
    "            x_pred[i] = np.exp(logx_pred)\n",
    "\n",
    "            # update recursion with realized x_t\n",
    "            last_logh = logh_t\n",
    "            last_logx = _safelog(x_test[i])\n",
    "\n",
    "        h_pred = np.exp(logh_fore)\n",
    "        return h_pred, x_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d6521-5e35-4c13-822d-4e6ed0a4a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.index.min(), df.index.max(), df.shape)\n",
    "print(series_x.isna().sum(), series_r.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf07cc4-3935-4bf0-99e2-1426e33730c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PRECONDITIONS ---\n",
    "assert \"RV_daily\" in df.columns, \"df must have column 'RV_daily' from SPY.csv\"\n",
    "assert \"r\" in df.columns,        \"df must have column 'r' from returns (crsp).csv\"\n",
    "assert isinstance(df.index, pd.DatetimeIndex), \"df.index must be DatetimeIndex\"\n",
    "\n",
    "df = df.sort_index()\n",
    "\n",
    "# If RV_daily is *volatility* (sigma), square it to variance for Realized GARCH.\n",
    "# If it's already variance, leave the next line as-is.\n",
    "series_x = df[\"RV_daily\"].astype(float)      # <- use as-is; square here if needed: series_x = (df[\"RV_daily\"].astype(float))**2\n",
    "series_r = df[\"r\"].astype(float)\n",
    "\n",
    "# Convert dates to monthly periods\n",
    "months = df.index.to_period(\"M\")\n",
    "all_months = pd.PeriodIndex(months.unique()).sort_values()\n",
    "\n",
    "lookback_months  = 42     # 3.5y train\n",
    "test_span_months = 1      # 1m test\n",
    "step_months      = 1      # slide monthly\n",
    "\n",
    "fold_results, param_store = [], []\n",
    "\n",
    "for i in range(lookback_months, len(all_months), step_months):\n",
    "    test_months  = all_months[i : i + test_span_months]\n",
    "    if len(test_months) == 0:\n",
    "        break\n",
    "    train_months = all_months[i - lookback_months : i]\n",
    "\n",
    "    tr_mask = months.isin(train_months)\n",
    "    te_mask = months.isin(test_months)\n",
    "\n",
    "    # Guard against empty folds\n",
    "    if tr_mask.sum() < 50 or te_mask.sum() == 0:\n",
    "        # not enough data in this fold—skip\n",
    "        continue\n",
    "\n",
    "    x_tr = series_x.loc[tr_mask].values\n",
    "    r_tr = series_r.loc[tr_mask].values\n",
    "    x_te = series_x.loc[te_mask].values\n",
    "    y_te = series_x.loc[te_mask]  # truth as Series for the index\n",
    "\n",
    "    # Fit per fold with basic retry on optimizer failure\n",
    "    try:\n",
    "        rg = RealizedGARCH11().fit(r_tr, x_tr)\n",
    "        if not getattr(rg, \"success_\", True):\n",
    "            # simple retry with slightly different start values (nudged beta/gamma)\n",
    "            start = np.array([-0.1, 0.92, 0.08, 0.0, 1.0, 0.0, 0.0, -2.0])\n",
    "            rg = RealizedGARCH11().fit(r_tr, x_tr, start=start)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] fold {str(test_months[0])} fit failed: {e}\")\n",
    "        continue\n",
    "\n",
    "    param_store.append(rg.theta_)\n",
    "\n",
    "    try:\n",
    "        h_pred, x_pred = rg.forecast_oos(r_tr, x_tr, x_te)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] fold {str(test_months[0])} forecast failed: {e}\")\n",
    "        continue\n",
    "\n",
    "    fold_df = pd.DataFrame(\n",
    "        {\n",
    "            \"RV_true\": y_te.values,\n",
    "            \"h_pred\":  h_pred,\n",
    "            \"x_pred\":  x_pred,\n",
    "            # safer than Period.strftime across pandas versions\n",
    "            \"fold_month\": str(test_months[0])\n",
    "        },\n",
    "        index=y_te.index,\n",
    "    )\n",
    "\n",
    "    fold_results.append(fold_df)\n",
    "\n",
    "# Concatenate all out-of-sample predictions\n",
    "if len(fold_results) == 0:\n",
    "    raise RuntimeError(\"No successful folds were produced. Check that df has enough overlap and that RV/returns contain valid numbers.\")\n",
    "cv_rg = pd.concat(fold_results).sort_index()\n",
    "\n",
    "print(f\"Folds estimated: {len(fold_results)}; OOS days: {cv_rg.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3effcde9-85d8-4b80-9d6a-705e86855530",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos = cv_rg.copy()\n",
    "mse_h,   ql_h = mse(oos[\"h_pred\"], oos[\"RV_true\"]), qlike(oos[\"h_pred\"], oos[\"RV_true\"])\n",
    "mse_x,   ql_x = mse(oos[\"x_pred\"], oos[\"RV_true\"]), qlike(oos[\"x_pred\"], oos[\"RV_true\"])\n",
    "\n",
    "print(\"OOS Realized GARCH vs RV_true\")\n",
    "print(f\"  h_pred: MSE={mse_h:,.6f}  QLIKE={ql_h:,.6f}\")\n",
    "print(f\"  x_pred: MSE={mse_x:,.6f}  QLIKE={ql_x:,.6f}\")\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(oos.index, oos[\"RV_true\"], label=\"Actual RV\", linewidth=1)\n",
    "plt.plot(oos.index, oos[\"h_pred\"],  label=\"Predicted (h_t)\", linewidth=1)\n",
    "plt.title(\"Realized GARCH(1,1): OOS Predicted vs Actual (variance)\")\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Variance\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(oos[\"RV_true\"], oos[\"h_pred\"], s=10, alpha=0.6)\n",
    "lims = [float(min(oos[\"RV_true\"].min(), oos[\"h_pred\"].min())),\n",
    "        float(max(oos[\"RV_true\"].max(), oos[\"h_pred\"].max()))]\n",
    "plt.plot(lims, lims, linewidth=1)\n",
    "plt.xlim(lims); plt.ylim(lims)\n",
    "plt.xlabel(\"Actual RV\"); plt.ylabel(\"Predicted (h_t)\")\n",
    "plt.title(\"OOS Predicted vs Actual (Realized GARCH)\"); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29fab6-d727-430e-8450-5c7279ab5aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
